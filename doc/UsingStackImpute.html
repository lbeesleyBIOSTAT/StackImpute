<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1" />

<meta name="author" content="Created by Dr. Lauren J Beesley. Contact: lbeesley@umich.edu" />


<title>UsingStackImpute</title>

<style type="text/css">
a.anchor-section {margin-left: 10px; visibility: hidden; color: inherit;}
a.anchor-section::before {content: '#';}
.hasAnchor:hover a.anchor-section {visibility: visible;}
</style>
<script>// Anchor sections v1.0 written by Atsushi Yasumoto on Oct 3rd, 2020.
document.addEventListener('DOMContentLoaded', function() {
  // Do nothing if AnchorJS is used
  if (typeof window.anchors === 'object' && anchors.hasOwnProperty('hasAnchorJSLink')) {
    return;
  }

  const h = document.querySelectorAll('h1, h2, h3, h4, h5, h6');

  // Do nothing if sections are already anchored
  if (Array.from(h).some(x => x.classList.contains('hasAnchor'))) {
    return null;
  }

  // Use section id when pandoc runs with --section-divs
  const section_id = function(x) {
    return ((x.classList.contains('section') || (x.tagName === 'SECTION'))
            ? x.id : '');
  };

  // Add anchors
  h.forEach(function(x) {
    const id = x.id || section_id(x.parentElement);
    if (id === '') {
      return null;
    }
    let anchor = document.createElement('a');
    anchor.href = '#' + id;
    anchor.classList = ['anchor-section'];
    x.classList.add('hasAnchor');
    x.appendChild(anchor);
  });
});
</script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css" data-origin="pandoc">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */

</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    for (var j = 0; j < rules.length; j++) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") continue;
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') continue;
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>



<style type="text/css">body {
background-color: #fff;
margin: 1em auto;
max-width: 700px;
overflow: visible;
padding-left: 2em;
padding-right: 2em;
font-family: "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif;
font-size: 14px;
line-height: 1.35;
}
#TOC {
clear: both;
margin: 0 0 10px 10px;
padding: 4px;
width: 400px;
border: 1px solid #CCCCCC;
border-radius: 5px;
background-color: #f6f6f6;
font-size: 13px;
line-height: 1.3;
}
#TOC .toctitle {
font-weight: bold;
font-size: 15px;
margin-left: 5px;
}
#TOC ul {
padding-left: 40px;
margin-left: -1.5em;
margin-top: 5px;
margin-bottom: 5px;
}
#TOC ul ul {
margin-left: -2em;
}
#TOC li {
line-height: 16px;
}
table {
margin: 1em auto;
border-width: 1px;
border-color: #DDDDDD;
border-style: outset;
border-collapse: collapse;
}
table th {
border-width: 2px;
padding: 5px;
border-style: inset;
}
table td {
border-width: 1px;
border-style: inset;
line-height: 18px;
padding: 5px 5px;
}
table, table th, table td {
border-left-style: none;
border-right-style: none;
}
table thead, table tr.even {
background-color: #f7f7f7;
}
p {
margin: 0.5em 0;
}
blockquote {
background-color: #f6f6f6;
padding: 0.25em 0.75em;
}
hr {
border-style: solid;
border: none;
border-top: 1px solid #777;
margin: 28px 0;
}
dl {
margin-left: 0;
}
dl dd {
margin-bottom: 13px;
margin-left: 13px;
}
dl dt {
font-weight: bold;
}
ul {
margin-top: 0;
}
ul li {
list-style: circle outside;
}
ul ul {
margin-bottom: 0;
}
pre, code {
background-color: #f7f7f7;
border-radius: 3px;
color: #333;
white-space: pre-wrap; 
}
pre {
border-radius: 3px;
margin: 5px 0px 10px 0px;
padding: 10px;
}
pre:not([class]) {
background-color: #f7f7f7;
}
code {
font-family: Consolas, Monaco, 'Courier New', monospace;
font-size: 85%;
}
p > code, li > code {
padding: 2px 0px;
}
div.figure {
text-align: center;
}
img {
background-color: #FFFFFF;
padding: 2px;
border: 1px solid #DDDDDD;
border-radius: 3px;
border: 1px solid #CCCCCC;
margin: 0 5px;
}
h1 {
margin-top: 0;
font-size: 35px;
line-height: 40px;
}
h2 {
border-bottom: 4px solid #f7f7f7;
padding-top: 10px;
padding-bottom: 2px;
font-size: 145%;
}
h3 {
border-bottom: 2px solid #f7f7f7;
padding-top: 10px;
font-size: 120%;
}
h4 {
border-bottom: 1px solid #f7f7f7;
margin-left: 8px;
font-size: 105%;
}
h5, h6 {
border-bottom: 1px solid #ccc;
font-size: 105%;
}
a {
color: #0033dd;
text-decoration: none;
}
a:hover {
color: #6666ff; }
a:visited {
color: #800080; }
a:visited:hover {
color: #BB00BB; }
a[href^="http:"] {
text-decoration: underline; }
a[href^="https:"] {
text-decoration: underline; }

code > span.kw { color: #555; font-weight: bold; } 
code > span.dt { color: #902000; } 
code > span.dv { color: #40a070; } 
code > span.bn { color: #d14; } 
code > span.fl { color: #d14; } 
code > span.ch { color: #d14; } 
code > span.st { color: #d14; } 
code > span.co { color: #888888; font-style: italic; } 
code > span.ot { color: #007020; } 
code > span.al { color: #ff0000; font-weight: bold; } 
code > span.fu { color: #900; font-weight: bold; } 
code > span.er { color: #a61717; background-color: #e3d2d2; } 
</style>




</head>

<body>




<h1 class="title toc-ignore">UsingStackImpute</h1>
<h4 class="author">Created by Dr. Lauren J Beesley. Contact: <a href="mailto:lbeesley@umich.edu" class="email">lbeesley@umich.edu</a></h4>
<h4 class="date">10 June, 2021</h4>



<p>In this vignette, we provide a brief introduction to using the R package <em>StackImpute</em>. The purpose of this package is to provide resources for performing data analysis in the presence of missing data through analysis of a stacked version of the multiply imputed data. We will not include technical details about this estimation approach and instead focus on implementation. For additional details about the estimation algorithm, we refer the reader to “A stacked approach for chained equations multiple imputation incorporating the substantive model” by Lauren J Beesley and Jeremy M G Taylor in <em>Biometrics</em> (2020) and “Accounting for not-at-random missingness through imputation stacking” by Lauren J Beesley and Jeremy M G Taylor currently on <em>arXiv</em>.</p>
<p>Many researchers have noted that we can do a “good” job estimating regression model parameters by analyzing a stacked version of multiply imputed data. However, estimation of standard errors has proven to be a challenging problem. We provide several estimation strategies and corresponding software for routine estimation as follows:</p>
<ol style="list-style-type: decimal">
<li><p>For glms and coxph model fits, the function <em>Louis_Information</em> will estimate the information matrix accounting for imputation uncertainty.</p></li>
<li><p>For more general likelihood-based inference, the function <em>Louis_Information_Custom</em> will take user-specified score and covariance matrices from stacked and weighted analysis. For this function, we note that the model-output dispersion parameter for the <em>glm</em> function in R is incorrect for stacked multiple imputations and provide a function to obtain a better estimate of the dispersion parameter.</p></li>
<li><p>The function <em>Bootstrap_Variance</em> implements a bootstrap-based method for estimating the covariance matrix as proposed by Dr. Paul Bernhardt in “A Comparison of Stacked and Pooled Multiple Imputation” at the Joint Statistical Meetings in 2019.</p></li>
<li><p>Finally, the function <em>Jackknife_Variance</em> implements a jackknife-based variant of the estimator proprosed by Dr. Paul Bernhardt.</p></li>
</ol>
<div id="example-analysis-using-standard-imputation-stacking" class="section level2">
<h2>Example analysis using standard imputation stacking</h2>
<p>First, we suppose that we have imputing missing data using usual multiple imputation incorporating both the outcome and covariates into the imputation. Instead of estimating outcome model parameters using Rubin’s combining rules, we propose stacking the multiple imputations to create one long dataset. Then, we perform a weighted analysis, where each subject is weighted by 1/M where M is the number of multiple imputations as follows:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1-1" data-line-number="1"><span class="kw">library</span>(dplyr)</a>
<a class="sourceLine" id="cb1-2" data-line-number="2"><span class="co">### Simulate Data</span></a>
<a class="sourceLine" id="cb1-3" data-line-number="3">Nobs =<span class="st"> </span><span class="dv">2000</span></a>
<a class="sourceLine" id="cb1-4" data-line-number="4">DAT =<span class="st"> </span>MASS<span class="op">::</span><span class="kw">mvrnorm</span>(<span class="dt">n =</span> Nobs, <span class="dt">mu =</span> <span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>), <span class="dt">Sigma =</span> <span class="kw">rbind</span>(<span class="kw">c</span>(<span class="dv">1</span>, <span class="fl">0.18</span>, <span class="fl">0.42</span>), <span class="kw">c</span>(<span class="fl">0.18</span>, <span class="fl">0.09</span>, <span class="fl">0.12</span>),<span class="kw">c</span>(<span class="fl">0.42</span>, <span class="fl">0.12</span>, <span class="fl">0.49</span> )))</a>
<a class="sourceLine" id="cb1-5" data-line-number="5">Y =<span class="st"> </span>DAT[,<span class="dv">1</span>]</a>
<a class="sourceLine" id="cb1-6" data-line-number="6">B =<span class="st"> </span>DAT[,<span class="dv">2</span>]</a>
<a class="sourceLine" id="cb1-7" data-line-number="7">X =<span class="st"> </span>DAT[,<span class="dv">3</span>]</a>
<a class="sourceLine" id="cb1-8" data-line-number="8">S =<span class="st"> </span><span class="kw">sample</span>(<span class="dt">x=</span><span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">1</span>), <span class="dt">size =</span> Nobs, <span class="dt">prob =</span> <span class="kw">c</span>(<span class="fl">0.5</span>,<span class="fl">0.5</span>), <span class="dt">replace =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb1-9" data-line-number="9">complete_cases =<span class="st"> </span><span class="kw">data.frame</span>(Y, X, B, S)[S <span class="op">==</span><span class="st"> </span><span class="dv">1</span>,] <span class="co">#complete case subjects only</span></a>
<a class="sourceLine" id="cb1-10" data-line-number="10">observed_data =<span class="st"> </span><span class="kw">data.frame</span>(Y, X, B, S) <span class="co">#data with missingness in B</span></a>
<a class="sourceLine" id="cb1-11" data-line-number="11">observed_data[S<span class="op">==</span><span class="dv">0</span>,<span class="st">'B'</span>] =<span class="st"> </span><span class="ot">NA</span></a>
<a class="sourceLine" id="cb1-12" data-line-number="12"></a>
<a class="sourceLine" id="cb1-13" data-line-number="13"><span class="co">### Step 1: Impute B|X,Y</span></a>
<a class="sourceLine" id="cb1-14" data-line-number="14">imputes =<span class="st"> </span>mice<span class="op">::</span><span class="kw">mice</span>(observed_data, <span class="dt">m=</span><span class="dv">50</span>, <span class="dt">method=</span><span class="st">&quot;norm&quot;</span>, <span class="dt">printFlag=</span>F, <span class="dt">maxit =</span> <span class="dv">1</span>)</a>
<a class="sourceLine" id="cb1-15" data-line-number="15">pred =<span class="st"> </span>imputes<span class="op">$</span>predictorMatrix </a>
<a class="sourceLine" id="cb1-16" data-line-number="16">pred[pred <span class="op">!=</span><span class="st"> </span><span class="dv">0</span>] =<span class="st"> </span><span class="dv">0</span></a>
<a class="sourceLine" id="cb1-17" data-line-number="17">pred[<span class="st">&quot;B&quot;</span>,<span class="st">&quot;X&quot;</span>] =<span class="st"> </span><span class="dv">1</span></a>
<a class="sourceLine" id="cb1-18" data-line-number="18">pred[<span class="st">&quot;B&quot;</span>,<span class="st">&quot;Y&quot;</span>] =<span class="st"> </span><span class="dv">1</span></a>
<a class="sourceLine" id="cb1-19" data-line-number="19">imputes =<span class="st"> </span>mice<span class="op">::</span><span class="kw">mice</span>(observed_data, <span class="dt">m=</span><span class="dv">50</span>, <span class="dt">predictorMatrix=</span>pred, <span class="dt">method=</span><span class="st">&quot;norm&quot;</span>, <span class="dt">printFlag=</span>F)</a>
<a class="sourceLine" id="cb1-20" data-line-number="20"></a>
<a class="sourceLine" id="cb1-21" data-line-number="21"><span class="co">### Step 2: Stack imputed datasets  </span></a>
<a class="sourceLine" id="cb1-22" data-line-number="22">stack =<span class="st"> </span>mice<span class="op">::</span><span class="kw">complete</span>(imputes, <span class="dt">action=</span><span class="st">&quot;long&quot;</span>, <span class="dt">include =</span> <span class="ot">FALSE</span>)</a>
<a class="sourceLine" id="cb1-23" data-line-number="23"></a>
<a class="sourceLine" id="cb1-24" data-line-number="24"><span class="co">### Step 3: Obtain weights</span></a>
<a class="sourceLine" id="cb1-25" data-line-number="25">stack<span class="op">$</span>wt =<span class="st"> </span><span class="dv">1</span></a>
<a class="sourceLine" id="cb1-26" data-line-number="26">stack =<span class="st"> </span><span class="kw">as.data.frame</span>(stack <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">group_by</span>(.id) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">mutate</span>(<span class="dt">wt =</span> wt <span class="op">/</span><span class="st"> </span><span class="kw">sum</span>(wt)))</a>
<a class="sourceLine" id="cb1-27" data-line-number="27"></a>
<a class="sourceLine" id="cb1-28" data-line-number="28"><span class="co">### Step 4: Point estimation</span></a>
<a class="sourceLine" id="cb1-29" data-line-number="29">fit =<span class="st"> </span><span class="kw">glm</span>(Y <span class="op">~</span>X <span class="op">+</span><span class="st"> </span>B, <span class="dt">data=</span>stack, <span class="dt">family=</span><span class="kw">gaussian</span>(), <span class="dt">weights =</span> stack<span class="op">$</span>wt)</a>
<a class="sourceLine" id="cb1-30" data-line-number="30"></a>
<a class="sourceLine" id="cb1-31" data-line-number="31"><span class="co">### Step 5a: Variance estimation option 1 (for glm and coxph models only)</span></a>
<a class="sourceLine" id="cb1-32" data-line-number="32">Info =<span class="st"> </span>StackImpute<span class="op">::</span><span class="kw">Louis_Information</span>(fit, stack, <span class="dt">M =</span> <span class="dv">50</span>)</a>
<a class="sourceLine" id="cb1-33" data-line-number="33">VARIANCE =<span class="st"> </span><span class="kw">diag</span>(<span class="kw">solve</span>(Info))</a>
<a class="sourceLine" id="cb1-34" data-line-number="34"></a>
<a class="sourceLine" id="cb1-35" data-line-number="35"><span class="co">### Step 5b: Variance estimation using custom score and covariance matrices (any model with corresponding likelihood)</span></a>
<a class="sourceLine" id="cb1-36" data-line-number="36">covariates =<span class="st"> </span><span class="kw">as.matrix</span>(<span class="kw">cbind</span>(<span class="dv">1</span>,stack<span class="op">$</span>X, stack<span class="op">$</span>B))</a>
<a class="sourceLine" id="cb1-37" data-line-number="37">score =<span class="st"> </span><span class="kw">sweep</span>(covariates,<span class="dv">1</span>,stack<span class="op">$</span>Y <span class="op">-</span><span class="st"> </span>covariates <span class="op">%*%</span><span class="st"> </span><span class="kw">matrix</span>(<span class="kw">coef</span>(fit)), <span class="st">'*'</span>)<span class="op">/</span>StackImpute<span class="op">::</span><span class="kw">glm.weighted.dispersion</span>(fit)</a>
<a class="sourceLine" id="cb1-38" data-line-number="38">covariance_weighted =<span class="st"> </span><span class="kw">summary</span>(fit)<span class="op">$</span>cov.unscaled<span class="op">*</span>StackImpute<span class="op">::</span><span class="kw">glm.weighted.dispersion</span>(fit) </a>
<a class="sourceLine" id="cb1-39" data-line-number="39">Info =<span class="st"> </span>StackImpute<span class="op">::</span><span class="kw">Louis_Information_Custom</span>(score, covariance_weighted, stack, <span class="dt">M =</span> <span class="dv">50</span>)</a>
<a class="sourceLine" id="cb1-40" data-line-number="40">VARIANCE_custom =<span class="st"> </span><span class="kw">diag</span>(<span class="kw">solve</span>(Info))</a>
<a class="sourceLine" id="cb1-41" data-line-number="41"></a>
<a class="sourceLine" id="cb1-42" data-line-number="42"><span class="co">### Step 5c: Variance estimation using bootstrap (any model with vcov method)</span></a>
<a class="sourceLine" id="cb1-43" data-line-number="43">bootcovar =<span class="st"> </span>StackImpute<span class="op">::</span><span class="kw">Bootstrap_Variance</span>(fit, stack, <span class="dt">M =</span> <span class="dv">50</span>, <span class="dt">n_boot =</span> <span class="dv">100</span>)</a>
<a class="sourceLine" id="cb1-44" data-line-number="44">VARIANCE_boot =<span class="st"> </span><span class="kw">diag</span>(bootcovar)</a>
<a class="sourceLine" id="cb1-45" data-line-number="45"></a>
<a class="sourceLine" id="cb1-46" data-line-number="46"><span class="co">### Step 5d: Variance estimation using jackknife (any model with vcov method)</span></a>
<a class="sourceLine" id="cb1-47" data-line-number="47">jackcovar =<span class="st"> </span>StackImpute<span class="op">::</span><span class="kw">Jackknife_Variance</span>(fit, stack, <span class="dt">M =</span> <span class="dv">50</span>)</a>
<a class="sourceLine" id="cb1-48" data-line-number="48">VARIANCE_jack =<span class="st"> </span><span class="kw">diag</span>(jackcovar)</a></code></pre></div>
</div>
<div id="example-analysis-using-modified-imputation-stacking-allowing-for-compatibility-of-the-imputation-and-analysis-models" class="section level2">
<h2>Example analysis using modified imputation stacking allowing for compatibility of the imputation and analysis models</h2>
<p>In Beesley and Taylor (2020) in <em>Biometrics</em>, we propose a modification to this data analysis pipeline that involves imputing missing covariates from distributions that do not condition on the outcome of interest and then performing a weighted analysis on the stacked data. In this case, weights are defined proportional to the distribution of the outcome given covariates in the complete case data. We can implement this modified analysis pipeline as follows:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb2-1" data-line-number="1"><span class="co">### Step 1: Impute B|X</span></a>
<a class="sourceLine" id="cb2-2" data-line-number="2">imputes =<span class="st"> </span>mice<span class="op">::</span><span class="kw">mice</span>(observed_data, <span class="dt">m=</span><span class="dv">50</span>, <span class="dt">method=</span><span class="st">&quot;norm&quot;</span>, <span class="dt">printFlag=</span>F, <span class="dt">maxit =</span> <span class="dv">1</span>)</a>
<a class="sourceLine" id="cb2-3" data-line-number="3">pred =<span class="st"> </span>imputes<span class="op">$</span>predictorMatrix </a>
<a class="sourceLine" id="cb2-4" data-line-number="4">pred[pred <span class="op">!=</span><span class="st"> </span><span class="dv">0</span>] =<span class="st"> </span><span class="dv">0</span></a>
<a class="sourceLine" id="cb2-5" data-line-number="5">pred[<span class="st">&quot;B&quot;</span>,<span class="st">&quot;X&quot;</span>] =<span class="st"> </span><span class="dv">1</span></a>
<a class="sourceLine" id="cb2-6" data-line-number="6">imputes =<span class="st"> </span>mice<span class="op">::</span><span class="kw">mice</span>(observed_data, <span class="dt">m=</span><span class="dv">50</span>, <span class="dt">predictorMatrix=</span>pred, <span class="dt">method=</span><span class="st">&quot;norm&quot;</span>, <span class="dt">printFlag=</span>F)</a>
<a class="sourceLine" id="cb2-7" data-line-number="7"></a>
<a class="sourceLine" id="cb2-8" data-line-number="8"><span class="co">### Step 2: Stack imputed datasets  </span></a>
<a class="sourceLine" id="cb2-9" data-line-number="9">stack =<span class="st"> </span>mice<span class="op">::</span><span class="kw">complete</span>(imputes, <span class="dt">action=</span><span class="st">&quot;long&quot;</span>, <span class="dt">include =</span> <span class="ot">FALSE</span>)</a>
<a class="sourceLine" id="cb2-10" data-line-number="10"></a>
<a class="sourceLine" id="cb2-11" data-line-number="11"><span class="co">### Step 3: Obtain weights</span></a>
<a class="sourceLine" id="cb2-12" data-line-number="12">fit_cc =<span class="st"> </span><span class="kw">glm</span>(Y <span class="op">~</span><span class="st"> </span>X <span class="op">+</span><span class="st"> </span>B, <span class="dt">family=</span><span class="st">'gaussian'</span>, <span class="dt">data=</span> complete_cases)</a>
<a class="sourceLine" id="cb2-13" data-line-number="13">stack<span class="op">$</span>wt =<span class="st"> </span><span class="kw">dnorm</span>(stack<span class="op">$</span>Y,<span class="dt">mean =</span> <span class="kw">predict</span>(fit_cc, <span class="dt">newdata =</span> stack), <span class="dt">sd =</span> <span class="kw">sqrt</span>(<span class="kw">summary</span>(fit_cc)<span class="op">$</span>dispersion))</a>
<a class="sourceLine" id="cb2-14" data-line-number="14">stack =<span class="st"> </span><span class="kw">as.data.frame</span>(stack <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">group_by</span>(.id) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">mutate</span>(<span class="dt">wt =</span> wt <span class="op">/</span><span class="st"> </span><span class="kw">sum</span>(wt)))</a>
<a class="sourceLine" id="cb2-15" data-line-number="15"></a>
<a class="sourceLine" id="cb2-16" data-line-number="16"><span class="co">### Step 4: Point estimation</span></a>
<a class="sourceLine" id="cb2-17" data-line-number="17">fit =<span class="st"> </span><span class="kw">glm</span>(Y <span class="op">~</span>X <span class="op">+</span><span class="st"> </span>B, <span class="dt">data=</span>stack, <span class="dt">family=</span><span class="kw">gaussian</span>(), <span class="dt">weights =</span> stack<span class="op">$</span>wt)</a>
<a class="sourceLine" id="cb2-18" data-line-number="18"></a>
<a class="sourceLine" id="cb2-19" data-line-number="19"><span class="co">### Any one of the above variance estimation strategies can then be applied.</span></a></code></pre></div>
</div>
<div id="a-note-on-stack-structure" class="section level2">
<h2>A note on stack structure</h2>
<p>We can equivalently performed our proposed data analysis using “short” stacked dataset in which subjects with fully-observed data only appear once. The advantage of this approach is that estimation may be faster and the stacked dataset may be much smaller. We can perform the above analysis using the shorter stack obtained below</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb3-1" data-line-number="1"><span class="co">### Step 2: Stack imputed datasets  </span></a>
<a class="sourceLine" id="cb3-2" data-line-number="2">stack =<span class="st"> </span>mice<span class="op">::</span><span class="kw">complete</span>(imputes, <span class="dt">action=</span><span class="st">&quot;long&quot;</span>, <span class="dt">include =</span> <span class="ot">FALSE</span>)</a>
<a class="sourceLine" id="cb3-3" data-line-number="3">cc =<span class="st"> </span><span class="kw">unique</span>(stack<span class="op">$</span>.id[stack<span class="op">$</span>S <span class="op">==</span><span class="st"> </span><span class="dv">1</span>])</a>
<a class="sourceLine" id="cb3-4" data-line-number="4">stack_short =<span class="st"> </span><span class="kw">rbind</span>(stack[stack<span class="op">$</span>S<span class="op">==</span><span class="dv">0</span>,], stack[stack<span class="op">$</span>S<span class="op">==</span><span class="dv">1</span> <span class="op">&amp;</span><span class="st"> </span><span class="op">!</span><span class="kw">duplicated</span>(stack<span class="op">$</span>.id),])</a></code></pre></div>
</div>
<div id="example-analysis-addressing-not-at-random-missingness-through-stacked-and-weighted-analysis" class="section level2">
<h2>Example analysis addressing not-at-random missingness through stacked and weighted analysis</h2>
<p>In Beesley and Taylor (2021) on <em>arXiv</em>, we propose another modification to this data analysis pipeline that accounts for not-at-random missingness through weighted analysis of stacked multiple imputations. Weights are a simple function of the imputed data and assumptions about the missingness mechanism. In the special case where missingness follows a logistic regression, the weights take a very simple form as shown.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb4-1" data-line-number="1"><span class="co">### Simulate Data</span></a>
<a class="sourceLine" id="cb4-2" data-line-number="2">prob_obs =<span class="st"> </span><span class="kw">exp</span>(<span class="dv">2</span><span class="op">*</span>B <span class="op">+</span><span class="st"> </span><span class="dv">1</span><span class="op">*</span>Y)<span class="op">/</span>(<span class="dv">1</span><span class="op">+</span><span class="kw">exp</span>(<span class="dv">2</span><span class="op">*</span>B <span class="op">+</span><span class="st"> </span><span class="dv">1</span><span class="op">*</span>Y))</a>
<a class="sourceLine" id="cb4-3" data-line-number="3">S_mnar =<span class="st"> </span><span class="kw">as.numeric</span>(prob_obs <span class="op">&gt;</span><span class="st"> </span><span class="kw">runif</span>(Nobs,<span class="dv">0</span>,<span class="dv">1</span>))</a>
<a class="sourceLine" id="cb4-4" data-line-number="4">complete_cases =<span class="st"> </span><span class="kw">data.frame</span>(Y, X, B, <span class="dt">S=</span>S_mnar)[S_mnar <span class="op">==</span><span class="st"> </span><span class="dv">1</span>,] <span class="co">#complete case subjects only</span></a>
<a class="sourceLine" id="cb4-5" data-line-number="5">observed_data_mnar =<span class="st"> </span><span class="kw">data.frame</span>(Y, X, B, <span class="dt">S=</span>S_mnar) <span class="co">#data with missingness in B</span></a>
<a class="sourceLine" id="cb4-6" data-line-number="6">observed_data_mnar[S_mnar<span class="op">==</span><span class="dv">0</span>,<span class="st">'B'</span>] =<span class="st"> </span><span class="ot">NA</span></a>
<a class="sourceLine" id="cb4-7" data-line-number="7"></a>
<a class="sourceLine" id="cb4-8" data-line-number="8"><span class="co">### Step 1: Impute B|X,Y</span></a>
<a class="sourceLine" id="cb4-9" data-line-number="9">imputes_mnar =<span class="st"> </span>mice<span class="op">::</span><span class="kw">mice</span>(observed_data_mnar, <span class="dt">m=</span><span class="dv">50</span>, <span class="dt">method=</span><span class="st">&quot;norm&quot;</span>, <span class="dt">printFlag=</span>F, <span class="dt">maxit =</span> <span class="dv">1</span>)</a>
<a class="sourceLine" id="cb4-10" data-line-number="10">pred =<span class="st"> </span>imputes_mnar<span class="op">$</span>predictorMatrix </a>
<a class="sourceLine" id="cb4-11" data-line-number="11">pred[pred <span class="op">!=</span><span class="st"> </span><span class="dv">0</span>] =<span class="st"> </span><span class="dv">0</span></a>
<a class="sourceLine" id="cb4-12" data-line-number="12">pred[<span class="st">&quot;B&quot;</span>,<span class="st">&quot;X&quot;</span>] =<span class="st"> </span><span class="dv">1</span></a>
<a class="sourceLine" id="cb4-13" data-line-number="13">pred[<span class="st">&quot;B&quot;</span>,<span class="st">&quot;Y&quot;</span>] =<span class="st"> </span><span class="dv">1</span></a>
<a class="sourceLine" id="cb4-14" data-line-number="14">imputes_mnar =<span class="st"> </span>mice<span class="op">::</span><span class="kw">mice</span>(observed_data_mnar, <span class="dt">m=</span><span class="dv">50</span>, <span class="dt">predictorMatrix=</span>pred, <span class="dt">method=</span><span class="st">&quot;norm&quot;</span>, <span class="dt">printFlag=</span>F)</a>
<a class="sourceLine" id="cb4-15" data-line-number="15"></a>
<a class="sourceLine" id="cb4-16" data-line-number="16"><span class="co">### Step 2: Stack imputed datasets</span></a>
<a class="sourceLine" id="cb4-17" data-line-number="17">stack =<span class="st"> </span>mice<span class="op">::</span><span class="kw">complete</span>(imputes_mnar, <span class="dt">action=</span><span class="st">&quot;long&quot;</span>, <span class="dt">include =</span> <span class="ot">FALSE</span>)</a>
<a class="sourceLine" id="cb4-18" data-line-number="18"></a>
<a class="sourceLine" id="cb4-19" data-line-number="19"><span class="co">### Step 3: Obtain weights</span></a>
<a class="sourceLine" id="cb4-20" data-line-number="20">phi1_assumed =<span class="st"> </span><span class="dv">2</span></a>
<a class="sourceLine" id="cb4-21" data-line-number="21">stack<span class="op">$</span>wt =<span class="st"> </span><span class="kw">exp</span>(<span class="op">-</span>phi1_assumed<span class="op">*</span>stack<span class="op">$</span>B)</a>
<a class="sourceLine" id="cb4-22" data-line-number="22">stack =<span class="st"> </span><span class="kw">as.data.frame</span>(stack <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">group_by</span>(.id) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">mutate</span>(<span class="dt">wt =</span> wt <span class="op">/</span><span class="st"> </span><span class="kw">sum</span>(wt)))</a>
<a class="sourceLine" id="cb4-23" data-line-number="23"></a>
<a class="sourceLine" id="cb4-24" data-line-number="24"><span class="co">### Step 4: Point estimation</span></a>
<a class="sourceLine" id="cb4-25" data-line-number="25">fit =<span class="st"> </span><span class="kw">glm</span>(Y <span class="op">~</span>X <span class="op">+</span><span class="st"> </span>B, <span class="dt">data=</span>stack, <span class="dt">family=</span><span class="kw">gaussian</span>(), <span class="dt">weights =</span> stack<span class="op">$</span>wt)</a>
<a class="sourceLine" id="cb4-26" data-line-number="26"></a>
<a class="sourceLine" id="cb4-27" data-line-number="27"><span class="co">### Any one of the above variance estimation strategies can then be applied.</span></a></code></pre></div>
</div>
<div id="example-analysis-addressing-not-at-random-missingness-using-the-method-of-tompsett-et-al.-2018" class="section level2">
<h2>Example analysis addressing not-at-random missingness using the method of Tompsett et al. (2018)</h2>
<p>In Tompsett et al. (2018) in <em>Statistics in Medicine</em>, researchers explore an alternative strategy for addressing not-at-random missingness. These researchers handle MNAR missingness by positing a pattern mixture model structure for the imputation models, where the adjusted association between a covariate’s value and its own missingness is treated as a fixed sensitivity analysis-type parameter.</p>
<!-- results = c() -->
<!-- resultsTomp = c() -->
<!-- theta = c() -->
<!-- for(i in c(1:100)){ -->
<!-- S_mnar = as.numeric(prob_obs > runif(Nobs,0,1)) -->
<!-- fit = glm(S_mnar~X+B+Y, family = 'binomial') -->
<!-- fitTomp = glm(B~X+Y+as.numeric(1-S_mnar), family = 'gaussian') -->
<!-- fitTheta = glm(Y~X+B, family = 'gaussian') -->
<!-- results = rbind(results, as.numeric(coef(fit))) -->
<!-- resultsTomp = rbind(resultsTomp, as.numeric(coef(fitTomp))) -->
<!-- theta = rbind(theta, as.numeric(coef(fitTheta))) -->
<!-- } -->
<!-- apply(results[,2:4],2,mean) -->
<!-- apply(resultsTomp[,2:4],2,mean) -->
<!-- apply(theta[,2:3],2,mean) -->
<!-- plot(B[S_mnar == 1]) -->
<!-- points(B[S_mnar == 0], col = 'red') -->
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb5-1" data-line-number="1"><span class="co">### Imputation Function (modified version of mice::mice.impute.mnar.norm())</span></a>
<a class="sourceLine" id="cb5-2" data-line-number="2">mice.impute.mnar.norm2 =<span class="st"> </span><span class="cf">function</span> (y, ry, x, <span class="dt">wy =</span> <span class="ot">NULL</span>, <span class="dt">ums =</span> <span class="ot">NULL</span>, <span class="dt">umx =</span> <span class="ot">NULL</span>, ...){</a>
<a class="sourceLine" id="cb5-3" data-line-number="3">  u &lt;-<span class="st"> </span>mice<span class="op">:::</span><span class="kw">parse.ums</span>(x, <span class="dt">ums =</span> ums, <span class="dt">umx =</span> umx, ...)</a>
<a class="sourceLine" id="cb5-4" data-line-number="4">  <span class="cf">if</span> (<span class="kw">is.null</span>(wy))</a>
<a class="sourceLine" id="cb5-5" data-line-number="5">    wy &lt;-<span class="st"> </span><span class="op">!</span>ry</a>
<a class="sourceLine" id="cb5-6" data-line-number="6">  x &lt;-<span class="st"> </span><span class="kw">cbind</span>(<span class="dv">1</span>, <span class="kw">as.matrix</span>(x))</a>
<a class="sourceLine" id="cb5-7" data-line-number="7">  parm &lt;-<span class="st"> </span>mice<span class="op">:::</span><span class="kw">.norm.draw</span>(y, ry, x, ...)</a>
<a class="sourceLine" id="cb5-8" data-line-number="8">  <span class="kw">return</span>(x[wy, ] <span class="op">%*%</span><span class="st"> </span>parm<span class="op">$</span>beta <span class="op">+</span><span class="st"> </span><span class="kw">as.matrix</span>(u<span class="op">$</span>x[wy, ]) <span class="op">%*%</span><span class="st"> </span><span class="kw">as.matrix</span>(u<span class="op">$</span>delta) <span class="op">+</span><span class="st"> </span><span class="kw">rnorm</span>(<span class="kw">sum</span>(wy)) <span class="op">*</span>parm<span class="op">$</span>sigma)</a>
<a class="sourceLine" id="cb5-9" data-line-number="9">}</a>
<a class="sourceLine" id="cb5-10" data-line-number="10"></a>
<a class="sourceLine" id="cb5-11" data-line-number="11"><span class="co">### *Ideal* pattern mixture model offset parameter for these simulated data:</span></a>
<a class="sourceLine" id="cb5-12" data-line-number="12">delta1_assumed =<span class="st"> </span><span class="fl">-0.087</span></a>
<a class="sourceLine" id="cb5-13" data-line-number="13"></a>
<a class="sourceLine" id="cb5-14" data-line-number="14"><span class="co">### Step 1: Impute B|X,Y,S</span></a>
<a class="sourceLine" id="cb5-15" data-line-number="15">mnar.blot &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">B =</span> <span class="kw">list</span>(<span class="dt">ums =</span><span class="kw">paste0</span>(<span class="st">'-'</span>,<span class="kw">abs</span>(delta1_assumed)))) </a>
<a class="sourceLine" id="cb5-16" data-line-number="16">imputes_pmm =<span class="st"> </span>mice<span class="op">::</span><span class="kw">mice</span>(observed_data_mnar, <span class="dt">m=</span><span class="dv">50</span>, <span class="dt">method=</span><span class="st">&quot;mnar.norm2&quot;</span>, <span class="dt">printFlag=</span>F, <span class="dt">maxit =</span> <span class="dv">1</span>, <span class="dt">blots =</span> mnar.blot)</a>
<a class="sourceLine" id="cb5-17" data-line-number="17">pred =<span class="st"> </span>imputes_pmm<span class="op">$</span>predictorMatrix </a>
<a class="sourceLine" id="cb5-18" data-line-number="18">pred[pred <span class="op">!=</span><span class="st"> </span><span class="dv">0</span>] =<span class="st"> </span><span class="dv">0</span></a>
<a class="sourceLine" id="cb5-19" data-line-number="19">pred[<span class="st">&quot;B&quot;</span>,<span class="st">&quot;X&quot;</span>] =<span class="st"> </span><span class="dv">1</span></a>
<a class="sourceLine" id="cb5-20" data-line-number="20">pred[<span class="st">&quot;B&quot;</span>,<span class="st">&quot;Y&quot;</span>] =<span class="st"> </span><span class="dv">1</span></a>
<a class="sourceLine" id="cb5-21" data-line-number="21">imputes_pmm =<span class="st"> </span>mice<span class="op">::</span><span class="kw">mice</span>(observed_data_mnar, <span class="dt">m=</span><span class="dv">50</span>, <span class="dt">predictorMatrix=</span>pred, <span class="dt">method=</span><span class="st">&quot;mnar.norm2&quot;</span>, <span class="dt">printFlag=</span>F, <span class="dt">blots =</span> mnar.blot)</a>
<a class="sourceLine" id="cb5-22" data-line-number="22"></a>
<a class="sourceLine" id="cb5-23" data-line-number="23"><span class="co">### Step 2: Apply Rubin's Rules to obtain point estimates and standard errors</span></a>
<a class="sourceLine" id="cb5-24" data-line-number="24">fit =<span class="st"> </span><span class="kw">summary</span>(<span class="kw">pool</span>(<span class="kw">with</span>(imputes_pmm,<span class="kw">glm</span>(Y <span class="op">~</span><span class="st"> </span>X <span class="op">+</span><span class="st"> </span>B, <span class="dt">family=</span><span class="kw">gaussian</span>()))))</a>
<a class="sourceLine" id="cb5-25" data-line-number="25">param =<span class="st"> </span>fit<span class="op">$</span>estimate</a>
<a class="sourceLine" id="cb5-26" data-line-number="26">VARIANCE =<span class="st"> </span>(fit<span class="op">$</span>std.error)<span class="op">^</span><span class="dv">2</span></a></code></pre></div>
</div>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
